> Storing all blocks of a large file on consecutive disk blocks would 
> minimize seeks during sequential file reads. Why is it impractical to do so? 
> What do operating systems do instead, to minimize the number of seeks during 
> sequential reads? 

--------------------------------

Reading data sequentially from a large file could be done with only one seek 
if the entire file was stored on consecutive disk blocks. Ensuring availability
of large numbers of consecutive free blocks is not easy, since files are created
and deleted, resulting in fragmentation of the free blocks on disks. Operating systems
allocate blocks on large but fixed-sized sequential extents instead, and only one seek 
is required per extent. 