> Current generation CPUs include an _instruction cache_, which caches recently
> used instructions. A function call then has a significant overhead because the 
> set of instructions being executed changes, resulting in cache misses on the 
> instruction cache. 
> 
> a. Explain why producer-driven pipelining with buffering is likely to result 
> in a better instruction cache hit rate, as compared to demand-driven pipelining. 
> 
> b. Explain why modifying demand-driven pipelining by generating multiple results on
> one call to _next()_, and returning them together, can improve the instruction 
> cache hit rate. 

--------------------------------

> a. Explain why producer-driven pipelining with buffering is likely to result 
> in a better instruction cache hit rate, as compared to demand-driven pipelining. 

Producer-driven pipelining executes the same set of instructions to generate multiple 
tuples by consuming already generated tuples from the inputs. Thus instruction cache hits 
will be more. In comparison, demand-driven pipelining switches from the instructions of one 
function to another for each tuple, resulting in more misses. 

> b. Explain why modifying demand-driven pipelining by generating multiple results on
> one call to _next()_, and returning them together, can improve the instruction 
> cache hit rate. 

By generating multiple results at one go, a _next()_ function would receive multiple 
tuples in its inputs and have a loop that generates multiple tuples for its output 
without switching execution to another function. Thus, the instruction cache hit rate 
can be expected to improve.  